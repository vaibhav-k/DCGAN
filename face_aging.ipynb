{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset from https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !wget https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\n",
    "# !tar -xvf wiki_crop.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import datetime\n",
    "from keras import Input, Model\n",
    "from keras.applications import InceptionResNetV2\n",
    "from keras import backend as K\n",
    "from keras.layers import (Conv2D, Flatten, Dense, BatchNormalization, Reshape,\n",
    "                          concatenate, LeakyReLU, Lambda, Activation,\n",
    "                          UpSampling2D, Dropout)\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras_preprocessing import image\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_encoder():\n",
    "    \"\"\"\n",
    "    Build the encoder network that encodes an image (x) to a latent vector (z)\n",
    "    or a latent vector representation.\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "\n",
    "    # 1st convolutional block\n",
    "    enc = Conv2D(filters=32, kernel_size=5, strides=2,\n",
    "                 padding=\"same\")(input_layer)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 2nd convolutional block\n",
    "    enc = Conv2D(filters=64, kernel_size=5, strides=2, padding=\"same\")(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 3rd convolutional block\n",
    "    enc = Conv2D(filters=128, kernel_size=5, strides=2, padding=\"same\")(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 4th convolutional block\n",
    "    enc = Conv2D(filters=256, kernel_size=5, strides=2, padding=\"same\")(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # flattening layer\n",
    "    enc = Flatten()(enc)\n",
    "\n",
    "    # 1st fully-connected Layer\n",
    "    enc = Dense(4096)(enc)\n",
    "    enc = BatchNormalization()(enc)\n",
    "    enc = LeakyReLU(alpha=0.2)(enc)\n",
    "\n",
    "    # 2nd fully-connected Layer\n",
    "    enc = Dense(100)(enc)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[input_layer], outputs=[enc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_generator():\n",
    "    \"\"\"\n",
    "    Build the Generator.\n",
    "    It takes a 100-dimensional vector z and generates an image with a dimension of (64, 64, 3).\n",
    "    \"\"\"\n",
    "    # define the hyperparameters\n",
    "    latent_dims = 100\n",
    "    num_classes = 6\n",
    "\n",
    "    input_z_noise = Input(shape=(latent_dims,))\n",
    "    input_label = Input(shape=(num_classes,))\n",
    "\n",
    "    # the generator will take both the noise vector and desired class label as input\n",
    "    x = concatenate([input_z_noise, input_label])\n",
    "\n",
    "    # 1st fully-connected block\n",
    "    x = Dense(2048, input_dim=latent_dims + num_classes)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    # 2nd fully-connected block\n",
    "    x = Dense(256 * 8 * 8)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Reshape((8, 8, 256))(x)\n",
    "\n",
    "    # 1st upsampling block\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=128, kernel_size=5, padding=\"same\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 2nd upsampling block\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=64, kernel_size=5, padding=\"same\")(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 3rd upsampling block\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(filters=3, kernel_size=5, padding=\"same\")(x)\n",
    "    x = Activation(\"tanh\")(x)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[input_z_noise, input_label], outputs=[x])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_label_input(x):\n",
    "    \"\"\"\n",
    "    Expand label_input so that it has a shape of (32, 32, 6) and not (6,)\n",
    "    \"\"\"\n",
    "    x = K.expand_dims(x, axis=1)\n",
    "    x = K.expand_dims(x, axis=1)\n",
    "    x = K.tile(x, [1, 32, 32, 1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator():\n",
    "    \"\"\"\n",
    "    Create a CNN-based Discriminator\n",
    "    \"\"\"\n",
    "    # define the hyperparameters\n",
    "    input_shape = (64, 64, 3)\n",
    "    label_shape = (6, )\n",
    "    image_input = Input(shape=input_shape)\n",
    "    label_input = Input(shape=label_shape)\n",
    "\n",
    "    # 1st convolutional block for the image input\n",
    "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(image_input)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    label_input1 = Lambda(expand_label_input)(label_input)\n",
    "    x = concatenate([x, label_input1], axis=3)\n",
    "\n",
    "    # 1st convolutional block\n",
    "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 2nd convolutional block\n",
    "    x = Conv2D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # 3rd convolutional block\n",
    "    x = Conv2D(512, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    # flattening layer\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # 1st fully-connected block\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[image_input, label_input], outputs=[x])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_fr_model(input_shape):\n",
    "    \"\"\"\n",
    "    Function to build the face recognition model.\n",
    "    \"\"\"\n",
    "    # using ResNet of 164 layers because it has excellent performance\n",
    "    resnet_model = InceptionResNetV2(include_top=False,\n",
    "                                     weights=\"imagenet\",\n",
    "                                     input_shape=input_shape,\n",
    "                                     pooling=\"avg\")\n",
    "    image_input = resnet_model.input\n",
    "    out = Dense(128)(x)\n",
    "    embedder_model = Model(inputs=[image_input], outputs=[out])\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    x = resnet_model.layers[-1].output\n",
    "    x = embedder_model(input_layer)\n",
    "    output = Lambda(lambda x: K.l2_normalize(x, axis=-1))(x)\n",
    "\n",
    "    model = Model(inputs=[input_layer], outputs=[output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_fr_combined_network(encoder, generator, fr_model):\n",
    "    \"\"\"\n",
    "    Function to build the face recognition combined network.\n",
    "    \"\"\"\n",
    "    # freeze the weights of the model responsible for facial recognition\n",
    "    fr_model.trainable = False\n",
    "\n",
    "    input_image = Input(shape=(64, 64, 3))\n",
    "    input_label = Input(shape=(6, ))\n",
    "\n",
    "    # encode the image to a latent vector representation\n",
    "    latent0 = encoder(input_image)\n",
    "\n",
    "    # generate artificial images\n",
    "    gen_images = generator([latent0, input_label])\n",
    "\n",
    "    # resize the images generated by the generator for input to the model responsible for facial recognition\n",
    "    resized_images = Lambda(\n",
    "        lambda x: K.resize_images(gen_images,\n",
    "                                  height_factor=2,\n",
    "                                  width_factor=2,\n",
    "                                  data_format=\"channels_last\"))(gen_images)\n",
    "    embeddings = fr_model(resized_images)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[input_image, input_label], outputs=[embeddings])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def image_resizer():\n",
    "    \"\"\"\n",
    "    Function to resize the images from a shape of (64, 64, 3) to a shape of (192, 192, 3)\n",
    "    \"\"\"\n",
    "    input_layer = Input(shape=(64, 64, 3))\n",
    "    factor = int(192 / 64)\n",
    "\n",
    "    resized_images = Lambda(\n",
    "        lambda x: K.resize_images(x,\n",
    "                                  height_factor=factor,\n",
    "                                  width_factor=factor,\n",
    "                                  data_format=\"channels_last\"))(input_layer)\n",
    "\n",
    "    # create the model and return it\n",
    "    model = Model(inputs=[input_layer], outputs=[resized_images])\n",
    "    return model\n",
    "\n",
    "\n",
    "def age_calculation(taken, dob):\n",
    "    \"\"\"\n",
    "    Function to calculate the age of the person from the serial date number and the year the photo was taken.\n",
    "    \"\"\"\n",
    "    birth = datetime.fromordinal(max(int(dob) - 366, 1))\n",
    "\n",
    "    if birth.month < 7:\n",
    "        return taken - birth.year\n",
    "    else:\n",
    "        return taken - birth.year - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(wiki_dir, dataset='wiki'):\n",
    "    \"\"\"\n",
    "    Function to retrieve images and their corresponding ages from the directory\n",
    "    \"\"\"\n",
    "    # load the .mat file\n",
    "    meta = loadmat(os.path.join(wiki_dir, \"{}.mat\".format(dataset)))\n",
    "\n",
    "    # load the list of all files\n",
    "    full_path = meta[dataset][0, 0][\"full_path\"][0]\n",
    "\n",
    "    # list of Matlab serial date numbers\n",
    "    dob = meta[dataset][0, 0][\"dob\"][0]\n",
    "\n",
    "    # list of years when photo was taken\n",
    "    photo_taken = meta[dataset][0, 0][\"photo_taken\"][0]\n",
    "\n",
    "    # calculate age for all dobs\n",
    "    age = [age_calculation(photo_taken[i], dob[i]) for i in range(len(dob))]\n",
    "\n",
    "    # create a list of tuples containing a pair of an image path and age\n",
    "    images = []\n",
    "    age_list = []\n",
    "    for index, image_path in enumerate(full_path):\n",
    "        images.append(image_path[0])\n",
    "        age_list.append(age[index])\n",
    "\n",
    "    # return a list of all images and respective age\n",
    "    return images, age_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_num_cat(age_list):\n",
    "    \"\"\"\n",
    "    Function to convert the age's numerical value to a category.\n",
    "    \n",
    "    The ranges are arbitrarily chosen and can be changed later.\n",
    "    \"\"\"\n",
    "\n",
    "    age_list_cat = []\n",
    "\n",
    "    for age in age_list:\n",
    "        if 0 < age <= 18:\n",
    "            cat = 0\n",
    "        elif 18 < age <= 29:\n",
    "            cat = 1\n",
    "        elif 29 < age <= 39:\n",
    "            cat = 2\n",
    "        elif 39 < age <= 49:\n",
    "            cat = 3\n",
    "        elif 49 < age <= 59:\n",
    "            cat = 4\n",
    "        elif age >= 60:\n",
    "            cat = 5\n",
    "        age_list_cat.append(cat)\n",
    "\n",
    "    return age_list_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_images(data_dir, image_paths, image_shape):\n",
    "    \"\"\"\n",
    "    Function to load all images and create an ndarray containing all images.\n",
    "    \"\"\"\n",
    "    images = None\n",
    "    for ind, image_path in enumerate(image_paths):\n",
    "        print(f\"index: {ind} and image path: {image_path}\")\n",
    "        try:\n",
    "            # load the image\n",
    "            loaded_image = image.load_img(os.path.join(data_dir, image_path),\n",
    "                                          target_size=image_shape)\n",
    "\n",
    "            # convert the PIL image to a NumPy ndarray\n",
    "            loaded_image = image.img_to_array(loaded_image)\n",
    "\n",
    "            # add another (batch) dimension\n",
    "            loaded_image = np.expand_dims(loaded_image, axis=0)\n",
    "\n",
    "            # concatenate all the images into an array\n",
    "            if images is None:\n",
    "                images = loaded_image\n",
    "            else:\n",
    "                images = np.concatenate([images, loaded_image], axis=0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error {e} at index {ind}\")\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance: https://en.wikipedia.org/wiki/Euclidean_distance\n",
    "    \"\"\"\n",
    "    return K.sqrt(K.sum(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "\n",
    "def save_img(img, path):\n",
    "    \"\"\"\n",
    "    Save an RGB image to the directory\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Image\")\n",
    "    plt.savefig(path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the training hyperparameters\n",
    "\"\"\"\n",
    "data_dir = \"./face_aging_data\"\n",
    "wiki_dir = os.path.join(data_dir, \"wiki_crop\")\n",
    "epochs = 500\n",
    "batch_size = 2\n",
    "image_shape = (64, 64, 3)\n",
    "z_shape = 100\n",
    "TRAIN_GAN = True\n",
    "TRAIN_ENCODER = False\n",
    "TRAIN_GAN_WITH_FR = False\n",
    "fr_image_shape = (192, 192, 3)\n",
    "\"\"\"\n",
    "Define the optimizers\n",
    "\"\"\"\n",
    "# optimizer for the discriminator\n",
    "dis_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
    "# optimizer for the generator\n",
    "gen_optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.999, epsilon=10e-8)\n",
    "# optimizer for the GAN network\n",
    "adversarial_optimizer = Adam(lr=0.0002,\n",
    "                             beta_1=0.5,\n",
    "                             beta_2=0.999,\n",
    "                             epsilon=10e-8)\n",
    "\"\"\"\n",
    "Build and compile the networks\n",
    "\"\"\"\n",
    "# the discriminator\n",
    "discriminator = define_discriminator()\n",
    "discriminator.compile(loss=[\"binary_crossentropy\"], optimizer=dis_optimizer)\n",
    "discriminator.trainable = False\n",
    "\n",
    "# the generator\n",
    "generator = define_generator()\n",
    "generator.compile(loss=[\"binary_crossentropy\"], optimizer=gen_optimizer)\n",
    "\n",
    "# the GAN\n",
    "input_z_noise = Input(shape=(100, ))\n",
    "input_label = Input(shape=(6, ))\n",
    "recons_images = generator([input_z_noise, input_label])\n",
    "valid = discriminator([recons_images, input_label])\n",
    "adversarial_model = Model(inputs=[input_z_noise, input_label], outputs=[valid])\n",
    "adversarial_model.compile(loss=[\"binary_crossentropy\"],\n",
    "                          optimizer=gen_optimizer)\n",
    "\n",
    "# load the dataset\n",
    "images, age_list = retrieve_data(wiki_dir=wiki_dir, dataset=\"wiki\")\n",
    "images = images[:1000]\n",
    "print(f\"Number of images = {len(images)}\")\n",
    "print(f\"age_list size = {len(age_list)}\")\n",
    "\n",
    "# convert the numeric age to categorical age\n",
    "age_cat = np.array(age_num_cat(age_list))\n",
    "final_age_cat = np.reshape(age_cat, [len(age_cat), 1])\n",
    "\n",
    "# get the unique classes by converting the list to a set\n",
    "classes = len(set(age_cat))\n",
    "y = to_categorical(final_age_cat, num_classes=len(set(age_cat)))\n",
    "\n",
    "loaded_images = retrieve_images(wiki_dir, images,\n",
    "                                (image_shape[0], image_shape[1]))\n",
    "\n",
    "# label smoothing\n",
    "real_labels = np.ones((batch_size, 1), dtype=np.float32) * 0.9\n",
    "fake_labels = np.zeros((batch_size, 1), dtype=np.float32) * 0.1\n",
    "\"\"\"\n",
    "Train the generator and the discriminator\n",
    "\"\"\"\n",
    "if TRAIN_GAN:\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch = {epoch}\")\n",
    "\n",
    "        gen_losses = []\n",
    "        dis_losses = []\n",
    "\n",
    "        number_of_batches = int(len(loaded_images) / batch_size)\n",
    "        print(f\"Number of batches = {number_of_batches}\")\n",
    "        for index in range(number_of_batches):\n",
    "            print(f\"Batch = {index + 1}\")\n",
    "\n",
    "            images_batch = loaded_images[index * batch_size:(index + 1) *\n",
    "                                         batch_size]\n",
    "            # normalize the images\n",
    "            images_batch = images_batch / 127.5 - 1.0\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "\n",
    "            y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "            # generate the noise vector\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "            \"\"\"\n",
    "            Train the discriminator network\n",
    "            \"\"\"\n",
    "\n",
    "            # generate fake images\n",
    "            initial_recon_images = generator.predict_on_batch(\n",
    "                [z_noise, y_batch])\n",
    "\n",
    "            d_loss_real = discriminator.train_on_batch([images_batch, y_batch],\n",
    "                                                       real_labels)\n",
    "            d_loss_fake = discriminator.train_on_batch(\n",
    "                [initial_recon_images, y_batch], fake_labels)\n",
    "\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            print(f\"Discriminator loss = {d_loss}\")\n",
    "            \"\"\"\n",
    "            Train the generator network\n",
    "            \"\"\"\n",
    "\n",
    "            # generate the noise vector\n",
    "            z_noise2 = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "\n",
    "            # generate the labels for the second input of the generator\n",
    "            random_labels = np.random.randint(0, 6, batch_size).reshape(-1, 1)\n",
    "            random_labels = to_categorical(random_labels, 6)\n",
    "\n",
    "            g_loss = adversarial_model.train_on_batch(\n",
    "                [z_noise2, random_labels], [1] * batch_size)\n",
    "\n",
    "            print(f\"Generator loss = {g_loss}\")\n",
    "\n",
    "            gen_losses.append(g_loss)\n",
    "            dis_losses.append(d_loss)\n",
    "        \"\"\"\n",
    "        Generate images after every 10th epoch\n",
    "        \"\"\"\n",
    "        if epoch % 10 == 0:\n",
    "            images_batch = loaded_images[0:batch_size]\n",
    "            # normalize the images\n",
    "            images_batch = images_batch / 127.5 - 1.0\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "\n",
    "            y_batch = y[0:batch_size]\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "\n",
    "            gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
    "\n",
    "            for ind, img in enumerate(gen_images[:5]):\n",
    "                save_img(img, path=f\"./results/img_{epoch}_{ind}.png\")\n",
    "\n",
    "    # save the trained networks\n",
    "    try:\n",
    "        generator.save_weights(\"generator.h5\")\n",
    "        discriminator.save_weights(\"discriminator.h5\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e} encountered\")\n",
    "\"\"\"\n",
    "Train the encoder\n",
    "\"\"\"\n",
    "\n",
    "if TRAIN_ENCODER:\n",
    "    # build and compile the encoder\n",
    "    encoder = define_encoder()\n",
    "    encoder.compile(loss=euclidean_distance, optimizer=\"adam\")\n",
    "\n",
    "    # load the generator's weights\n",
    "    try:\n",
    "        generator.load_weights(\"generator.h5\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error {e} encountered\")\n",
    "\n",
    "    z_i = np.random.normal(0, 1, size=(5000, z_shape))\n",
    "\n",
    "    y = np.random.randint(low=0, high=6, size=(5000, ), dtype=np.int64)\n",
    "    # get the unique classes by converting the list to a set\n",
    "    num_classes = len(set(y))\n",
    "    y = np.reshape(np.array(y), [len(y), 1])\n",
    "    y = to_categorical(y, num_classes=num_classes)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch = {epoch}\")\n",
    "\n",
    "        encoder_losses = []\n",
    "        number_of_batches = int(z_i.shape[0] / batch_size)\n",
    "        print(f\"Number of batches = {number_of_batches}\")\n",
    "        for index in range(number_of_batches):\n",
    "            print(f\"Batch = {index + 1}\")\n",
    "\n",
    "            z_batch = z_i[index * batch_size:(index + 1) * batch_size]\n",
    "            y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "            generated_images = generator.predict_on_batch([z_batch, y_batch])\n",
    "\n",
    "            # train the encoder model\n",
    "            encoder_loss = encoder.train_on_batch(generated_images, z_batch)\n",
    "            print(f\"Encoder loss = {encoder_loss}\")\n",
    "\n",
    "            encoder_losses.append(encoder_loss)\n",
    "\n",
    "    # save the encoder for further use\n",
    "    encoder.save_weights(\"encoder.h5\")\n",
    "\"\"\"\n",
    "Optimize the encoder and the generator\n",
    "\"\"\"\n",
    "if TRAIN_GAN_WITH_FR:\n",
    "\n",
    "    # load the encoder network\n",
    "    encoder = define_encoder()\n",
    "    encoder.load_weights(\"encoder.h5\")\n",
    "\n",
    "    # load the generator network\n",
    "    generator.load_weights(\"generator.h5\")\n",
    "\n",
    "    image_resizer = image_resizer()\n",
    "    image_resizer.compile(loss=[\"binary_crossentropy\"], optimizer=\"adam\")\n",
    "\n",
    "    # face recognition model\n",
    "    fr_model = define_fr_model(input_shape=fr_image_shape)\n",
    "    fr_model.compile(loss=[\"binary_crossentropy\"], optimizer=\"adam\")\n",
    "\n",
    "    # freeze the face recognition model's weights\n",
    "    fr_model.trainable = False\n",
    "\n",
    "    # input layers\n",
    "    input_image = Input(shape=(64, 64, 3))\n",
    "    input_label = Input(shape=(6, ))\n",
    "\n",
    "    # use the encoder and, then, the generator from its output\n",
    "    latent0 = encoder(input_image)\n",
    "    gen_images = generator([latent0, input_label])\n",
    "\n",
    "    # resize images to the desired shape\n",
    "    resized_images = Lambda(\n",
    "        lambda x: K.resize_images(gen_images,\n",
    "                                  height_factor=3,\n",
    "                                  width_factor=3,\n",
    "                                  data_format=\"channels_last\"))(gen_images)\n",
    "    embeddings = fr_model(resized_images)\n",
    "\n",
    "    # create a GAN and specify its inputs and outputs\n",
    "    fr_adversarial_model = Model(inputs=[input_image, input_label],\n",
    "                                 outputs=[embeddings])\n",
    "\n",
    "    # compile the GAN\n",
    "    fr_adversarial_model.compile(loss=euclidean_distance,\n",
    "                                 optimizer=adversarial_optimizer)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch = {epoch}\")\n",
    "\n",
    "        reconstruction_losses = []\n",
    "\n",
    "        number_of_batches = int(len(loaded_images) / batch_size)\n",
    "        print(f\"Number of batches = {number_of_batches}\")\n",
    "        for index in range(number_of_batches):\n",
    "            print(f\"Batch = {index + 1}\")\n",
    "\n",
    "            images_batch = loaded_images[index * batch_size:(index + 1) *\n",
    "                                         batch_size]\n",
    "            # normalize the images\n",
    "            images_batch = images_batch / 127.5 - 1.0\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "\n",
    "            y_batch = y[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "            images_batch_resized = image_resizer.predict_on_batch(images_batch)\n",
    "\n",
    "            real_embeddings = fr_model.predict_on_batch(images_batch_resized)\n",
    "\n",
    "            reconstruction_loss = fr_adversarial_model.train_on_batch(\n",
    "                [images_batch, y_batch], real_embeddings)\n",
    "\n",
    "            print(f\"Reconstruction loss = {reconstruction_loss}\")\n",
    "            reconstruction_losses.append(reconstruction_loss)\n",
    "        \"\"\"\n",
    "        Generate images\n",
    "        \"\"\"\n",
    "        if epoch % 10 == 0:\n",
    "            images_batch = loaded_images[0:batch_size]\n",
    "            # normalize the images\n",
    "            images_batch = images_batch / 127.5 - 1.0\n",
    "            images_batch = images_batch.astype(np.float32)\n",
    "\n",
    "            y_batch = y[0:batch_size]\n",
    "            z_noise = np.random.normal(0, 1, size=(batch_size, z_shape))\n",
    "\n",
    "            gen_images = generator.predict_on_batch([z_noise, y_batch])\n",
    "\n",
    "            for ind, img in enumerate(gen_images[:5]):\n",
    "                save_img(img, path=f\"./results/img_opt_{epoch}_{ind}.png\")\n",
    "\n",
    "    # save the improved weights for both models\n",
    "    generator.save_weights(\"generator_optimized.h5\")\n",
    "    encoder.save_weights(\"encoder_optimized.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
